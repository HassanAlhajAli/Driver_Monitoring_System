{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56e4529c",
   "metadata": {},
   "source": [
    "# DMS - Driver Monitoring System\n",
    "\n",
    "# Table of Contents\n",
    "1. [Importing Needed Packages](#import)\n",
    "2. [Declaring Constants](#constants)\n",
    "3. [Loading and Processing Data](#load)\n",
    "4. [Creating the Model](#create)\n",
    "5. [Saving the Model](#save)\n",
    "6. [Testing the Model Using Testing Data](#test)\n",
    "7. [Testing the Model Using a Webcam](#webcam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9105fe5",
   "metadata": {},
   "source": [
    "## Importing Needed Packages <a name=\"import\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32398b6a",
   "metadata": {
    "id": "32398b6a"
   },
   "outputs": [],
   "source": [
    "# Import Needed Packages\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import time\n",
    "import shutil\n",
    "from base64 import b64decode\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab.patches import cv2_imshow\n",
    "    from IPython.display import display, Javascript\n",
    "    from google.colab.output import eval_js\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c26715",
   "metadata": {},
   "source": [
    "## Declaring Constants <a name=\"constants\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MG62ZPdjTipw",
   "metadata": {
    "id": "MG62ZPdjTipw"
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "# Set the input image size to 224 pixels\n",
    "IMG_SIZE = 224\n",
    "\n",
    "MODEL_THRESHOLD = 0.8\n",
    "CLOSURE_DURATION_THRESHOLD = 3\n",
    "\n",
    "# Set the directories for the training and testing datasets\n",
    "# # # #\n",
    "if IN_COLAB:\n",
    "    # Running on Google Colab\n",
    "    print(\"Running on Google Colab\")\n",
    "    # Drive directories\n",
    "    BASE_ROOT_DIRECTORY = '/content/drive/MyDrive/Colab Notebooks'\n",
    "    TRAINING_DATA_DIRECTORY = f'{BASE_ROOT_DIRECTORY}/Input/training_data/'\n",
    "    VALIDATION_DATA_DIRECTORY = f'{BASE_ROOT_DIRECTORY}/Input/validation_data/'\n",
    "    TESTING_DATA_DIRECTORY = f'{BASE_ROOT_DIRECTORY}/Input/testing_data/'\n",
    "    MODELS_DIRECTORY = f'{BASE_ROOT_DIRECTORY}/models/'\n",
    "else:\n",
    "    # Running on a local environment\n",
    "    print(\"Running on a local environment\")\n",
    "    TRAINING_DATA_DIRECTORY = 'Input/training_data/'\n",
    "    VALIDATION_DATA_DIRECTORY = 'Input/validation_data/'\n",
    "    TESTING_DATA_DIRECTORY = 'Input/testing_data/'\n",
    "    MODELS_DIRECTORY = 'models/'\n",
    "# # # #\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M\")\n",
    "MODEL_FILE_NAME = f'dms_model-{timestr}.h5'\n",
    "MODEL_FILE_NAME = 'dms_model_final.h5'\n",
    "\n",
    "# Define the classes present in the dataset\n",
    "CLASSES = ['Closed_Eyes', 'Opened_Eyes']\n",
    "\n",
    "# Load cascade classifiers for detecting faces and eyes\n",
    "FACE_CASCADE = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "EYE_CASCADE = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190875bd",
   "metadata": {},
   "source": [
    "## Loading and Processing Data <a name=\"load\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77889c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator()\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "print('Loading training data...')\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    f'{TRAINING_DATA_DIRECTORY}',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary')\n",
    "\n",
    "print('Loading validation data...')\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    f'{VALIDATION_DATA_DIRECTORY}',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdc2078",
   "metadata": {},
   "source": [
    "## Creating the Model <a name=\"create\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecac6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained MobileNet model from Keras applications\n",
    "model = tf.keras.applications.mobilenet.MobileNet()\n",
    "\n",
    "# Print a summary of the model architecture\n",
    "print(model.summary())\n",
    "\n",
    "# Retrieve the input and output layers of the pre-trained model\n",
    "base_input = model.layers[0].input\n",
    "base_output = model.layers[-4].output\n",
    "\n",
    "# Flatten the output of the pre-trained model\n",
    "flat_layer = tf.keras.layers.Flatten()(base_output)\n",
    "\n",
    "# Add a dense layer and an activation function to the model\n",
    "final_output = tf.keras.layers.Dense(1)(flat_layer)\n",
    "final_output = tf.keras.layers.Activation('sigmoid')(final_output)\n",
    "\n",
    "# Create a new model with the pre-trained layers and the added layers\n",
    "result_model = tf.keras.Model(inputs=base_input, outputs=final_output)\n",
    "\n",
    "# Print a summary of the new model architecture\n",
    "print(result_model.summary())\n",
    "\n",
    "# Compile the new model with a binary crossentropy loss function, Adam optimizer, and accuracy metric\n",
    "result_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the new model to the training data with a specified batch size and number of epochs\n",
    "train_iterator = result_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.n // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.n // BATCH_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e80b9e4",
   "metadata": {},
   "source": [
    "## Evaluating and Saving the Model in Order to Choose the Best One<a name=\"evaluate\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f9a970",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = result_model.evaluate(validation_generator, steps=validation_generator.samples // BATCH_SIZE)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b8c888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "result_model.save(f'{MODELS_DIRECTORY}/{MODEL_FILE_NAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fcfc31",
   "metadata": {},
   "source": [
    "# Testing the Model Using Testing Data <a name=\"test\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b52938",
   "metadata": {
    "id": "b4b52938",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the trained DMS model\n",
    "dms_model = tf.keras.models.load_model(f'{MODELS_DIRECTORY}/{MODEL_FILE_NAME}')\n",
    "\n",
    "# Create an empty 2x2 matrix to hold the results of the test\n",
    "result = np.zeros((2, 2), dtype=int)\n",
    "\n",
    "counter_closed = 0\n",
    "counter_open = 0\n",
    "cnt = 0\n",
    "\n",
    "# Loop through each class (Closed_Eyes and Opened_Eyes)\n",
    "for category in CLASSES:\n",
    "    # Construct the path to the directory containing images for this category\n",
    "    path = os.path.join(TESTING_DATA_DIRECTORY, category)\n",
    "    # Determine the index of this category (0 or 1)\n",
    "    class_index = CLASSES.index(category)\n",
    "    \n",
    "    # Loop through each image in the directory\n",
    "    for img in os.listdir(path):\n",
    "        \n",
    "        cnt += 1\n",
    "        \n",
    "        # Read the image and convert it to grayscale\n",
    "        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "        # Convert the grayscale image to RGB and resize it to the expected size\n",
    "        back_to_rgb = cv2.cvtColor(img_array, cv2.COLOR_GRAY2RGB)\n",
    "        new_array = cv2.resize(back_to_rgb, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "        # Convert the resized image to a numpy array and reshape it to have 4 dimensions and\n",
    "        # normalize it by dividing pixels by 255.0\n",
    "        np_array = np.array(new_array).reshape(1, IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "        # Make a prediction on the image using the DMS model\n",
    "        pred = dms_model.predict(np_array)\n",
    "        # Convert the prediction to a binary classification (closed or open eyes) based on a threshold of 0.5\n",
    "        prediction = pred >= MODEL_THRESHOLD\n",
    "        \n",
    "        if category == 'Closed_Eyes' and pred > 0.5:\n",
    "            counter_closed += 1\n",
    "        \n",
    "        if category == 'Opened_Eyes' and pred < 0.5:\n",
    "            counter_open += 1\n",
    "        \n",
    "        \n",
    "        if cnt % 200 == 0:\n",
    "            print('counter_open = ', counter_open)\n",
    "            print('counter_closed = ', counter_closed)\n",
    "            \n",
    "        # Update the result matrix based on the true and predicted classes of the image\n",
    "        result[class_index][int(prediction[0, 0])] += 1\n",
    "\n",
    "print(f\"#True Pos = {result[1, 1]}\")\n",
    "print(f\"#True Neg = {result[0, 0]}\")\n",
    "print(f\"#False Pos = {result[1, 0]}\")\n",
    "print(f\"#False Neg = {result[0, 1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022dc153",
   "metadata": {},
   "source": [
    "# Testing the Model Using a Webcam <a name=\"webcam\"></a>\n",
    "* take_photo(...) is function that returns an image captured using JS. (The code snippet is provided by Google Colab)\n",
    "* test_on_webcam_browser() and test_on_webcam_local() are two functions that to try the model, test_on_webcam_browser() is to be used on a browser (in a Google Colab environment), while test_on_webcam_local() is to be used on a local machine with python environment. \n",
    "* The use of one of the functions is to be decided with the use of IN_COLAB boolean.\n",
    "* test_model_on_single_image(...) to test an image manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad52594",
   "metadata": {
    "id": "p46xT8Txi7Gw"
   },
   "outputs": [],
   "source": [
    "def take_photo(filename='photo.jpg', quality=1):\n",
    "    js = Javascript('''\n",
    "    async function takePhoto(quality) {\n",
    "      const div = document.createElement('div');\n",
    "      const capture = document.createElement('button');\n",
    "\n",
    "      const video = document.createElement('video');\n",
    "      video.style.display = 'block';\n",
    "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
    "\n",
    "      document.body.appendChild(div);\n",
    "      div.appendChild(video);\n",
    "      video.srcObject = stream;\n",
    "      await video.play();\n",
    "\n",
    "      // Resize the output to fit the video element.\n",
    "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
    "\n",
    "      const canvas = document.createElement('canvas');\n",
    "      canvas.width = video.videoWidth;\n",
    "      canvas.height = video.videoHeight;\n",
    "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
    "      stream.getVideoTracks()[0].stop();\n",
    "      div.remove();\n",
    "      return canvas.toDataURL('image/jpeg', quality);\n",
    "    }\n",
    "    ''')\n",
    "    display(js)\n",
    "    data = eval_js('takePhoto({})'.format(quality))\n",
    "    binary = b64decode(data.split(',')[1])\n",
    "    # convert the binary data to a numpy array\n",
    "    np_array = np.frombuffer(binary, np.uint8)\n",
    "    # decode the numpy array to an OpenCV image\n",
    "    img = cv2.imdecode(np_array, cv2.IMREAD_COLOR)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea01bc1",
   "metadata": {
    "id": "8ea01bc1"
   },
   "outputs": [],
   "source": [
    "def test_on_webcam_browser():\n",
    "    # Load the Deep Learning model for drowsiness detection\n",
    "    dms_model = tf.keras.models.load_model(f'{MODELS_DIRECTORY}/{MODEL_FILE_NAME}')\n",
    "\n",
    "    # Initialize the start time\n",
    "    start = time.time()\n",
    "\n",
    "    # Continuously capture frames from the webcam\n",
    "    while True:\n",
    "        # Capture a frame from the webcam\n",
    "        frame = take_photo()\n",
    "\n",
    "        # Detect eyes in the frame\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        eyes = EYE_CASCADE.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "        # Initialize variables for detected eyes and eye regions of interest (ROIs)\n",
    "        detected_eyes = None\n",
    "        eyes_roi = None\n",
    "\n",
    "        # Loop through the detected eyes\n",
    "        for x, y, w, h in eyes:\n",
    "            # Extract the region of interest (ROI) for the eyes\n",
    "            roi_gray = gray[y:y + h, x:x + w]\n",
    "            roi_color = frame[y:y + h, x:x + w]\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            # Detect eyes in the ROI\n",
    "            detected_eyes = EYE_CASCADE.detectMultiScale(roi_gray)\n",
    "\n",
    "            # If eyes are not detected in the ROI, print a message\n",
    "            if len(detected_eyes) == 0:\n",
    "                print(\"eyes not detected\")\n",
    "            else:\n",
    "                # Loop through the detected eyes in the ROI\n",
    "                for ex, ey, ew, eh in detected_eyes:\n",
    "                    # Extract the eye region of interest (ROI)\n",
    "                    eyes_roi = roi_color[ey:ey + eh, ex:ex + ew]\n",
    "\n",
    "        # Preprocess the eye region of interest (ROI) for the drowsiness detection model\n",
    "        if detected_eyes is None or eyes_roi is None:\n",
    "            status = \"No eyes detected\"\n",
    "        else:\n",
    "            final_image = cv2.resize(eyes_roi, (224, 224))\n",
    "            final_image = np.expand_dims(final_image, axis=0)\n",
    "#             final_image = final_image / 255.0\n",
    "\n",
    "            # Predict whether the eyes are open or closed using the drowsiness detection model\n",
    "            prediction = dms_model.predict(final_image)\n",
    "            print(\"Prediction \", prediction)\n",
    "\n",
    "            # Set the status to \"Open Eyes\" or \"Closed Eyes\" based on the prediction\n",
    "            if prediction > MODEL_THRESHOLD:\n",
    "                status = \"Open Eyes\"\n",
    "                start = time.time()\n",
    "            else:\n",
    "                status = \"Closed Eyes\"\n",
    "                current = time.time()\n",
    "                if current - start > CLOSURE_DURATION_THRESHOLD:\n",
    "                    print('DROWSINESS Detected')\n",
    "                    start = time.time()\n",
    "\n",
    "        # Detect faces in the frame\n",
    "        faces = FACE_CASCADE.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "        # Draw rectangles around the detected faces\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Display the status on the frame\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "        cv2.putText(frame,\n",
    "                    status,\n",
    "                    (10, 35),\n",
    "                    font, 0.8,\n",
    "                    (255, 255, 255),\n",
    "                    thickness=3)\n",
    "\n",
    "        cv2.putText(frame,\n",
    "                    status,\n",
    "                    (10, 35),\n",
    "                    font, 0.8,\n",
    "                    (0, 0, 0),\n",
    "                    thickness=2)\n",
    "\n",
    "        cv2_imshow(frame)\n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pKZeZmcyach1",
   "metadata": {
    "id": "pKZeZmcyach1"
   },
   "outputs": [],
   "source": [
    "def test_on_webcam_local():\n",
    "    # Load the Deep Learning model for drowsiness detection\n",
    "    dms_model = tf.keras.models.load_model(f'{MODELS_DIRECTORY}/{MODEL_FILE_NAME}')\n",
    "\n",
    "    # Open the local webcam\n",
    "    cap = cv2.VideoCapture(-1)\n",
    "\n",
    "    # Check if the webcam is opened correctly\n",
    "    if not cap.isOpened():\n",
    "        cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "    # Initialize the start time\n",
    "    start = time.time()\n",
    "\n",
    "    # Loop until 'q' is pressed or the webcam is stopped\n",
    "    while True:\n",
    "        # Capture the frame from the webcam\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Detect eyes in the frame\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        eyes = EYE_CASCADE.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "        detected_eyes = None\n",
    "        eyes_roi = None\n",
    "\n",
    "        # If eyes are detected, extract the region of interest (ROI) and resize it to (224, 224)\n",
    "        for x, y, w, h in eyes:\n",
    "            roi_gray = gray[y:y + h, x:x + w]\n",
    "            roi_color = frame[y:y + h, x:x + w]\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            detected_eyes = EYE_CASCADE.detectMultiScale(roi_gray)\n",
    "\n",
    "            if len(detected_eyes) == 0:\n",
    "                print(\"eyes not detected\")\n",
    "            else:\n",
    "                for ex, ey, ew, eh in detected_eyes:\n",
    "                    eyes_roi = roi_color[ey:ey + eh, ex:ex + ew]\n",
    "\n",
    "        drowsiness_detected = False\n",
    "\n",
    "        # Preprocess the ROI image and predict the output using the loaded Deep Learning model\n",
    "        if detected_eyes is None or eyes_roi is None:\n",
    "            status = \"No eyes detected\"\n",
    "        else:\n",
    "            final_image = cv2.resize(eyes_roi, (224, 224))\n",
    "\n",
    "            final_image = np.expand_dims(final_image, axis=0)\n",
    "#             final_image = (final_image-np.min(final_image))/(np.max(final_image)-np.min(final_image))\n",
    "\n",
    "            prediction = dms_model.predict(final_image)\n",
    "            print(\"Prediction \", prediction)\n",
    "\n",
    "            # If the prediction score is greater than 0.5, set the status to \"Open Eyes\" and update the start time\n",
    "            if prediction > MODEL_THRESHOLD:\n",
    "                status = \"Open Eyes\"\n",
    "                start = time.time()\n",
    "\n",
    "            # If the prediction score is less than or equal to 0.5, set the status to \"Closed Eyes\" If the duration\n",
    "            # of closed eyes is more than 3 seconds, print 'DROWSINESS Detected' and update the start time\n",
    "            else:\n",
    "                status = \"Closed Eyes\"\n",
    "                current = time.time()\n",
    "                if current - start > CLOSURE_DURATION_THRESHOLD:\n",
    "                    print('DROWSINESS Detected')\n",
    "                    drowsiness_detected = True\n",
    "                    if current - start > CLOSURE_DURATION_THRESHOLD + 2:\n",
    "                        start = time.time()\n",
    "\n",
    "        # Detect faces in the frame and draw rectangles around them\n",
    "        faces = FACE_CASCADE.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "\n",
    "        cv2.putText(frame,\n",
    "                    status,\n",
    "                    (10, 35),\n",
    "                    font, 0.8,\n",
    "                    (255, 255, 255),\n",
    "                    thickness=3)\n",
    "        cv2.putText(frame,\n",
    "                    status,\n",
    "                    (10, 35),\n",
    "                    font, 0.8,\n",
    "                    (0, 0, 0),\n",
    "                    thickness=2)\n",
    "\n",
    "        if drowsiness_detected:\n",
    "            import winsound\n",
    "            frequency = 2500  # Set Frequency To 2500 Hertz\n",
    "            duration = 1000  # Set Duration To 1000 ms == 1 second\n",
    "            winsound.Beep(frequency, duration)\n",
    "            cv2.putText(frame,\n",
    "                        'DROWSINESS Detected',\n",
    "                        (10, 70),\n",
    "                        font, 0.8,\n",
    "                        (0, 0, 255),\n",
    "                        3, )\n",
    "\n",
    "        cv2.imshow(\"DMS - Driver Monitoring System\", frame)\n",
    "\n",
    "        if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kstzjZDbafJM",
   "metadata": {
    "id": "kstzjZDbafJM"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "  test_on_webcam_browser()\n",
    "else:\n",
    "  test_on_webcam_local()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fee630",
   "metadata": {
    "id": "34fee630"
   },
   "outputs": [],
   "source": [
    "def test_model_on_single_image(image_path):\n",
    "    # Read in a grayscale image using OpenCV\n",
    "    img_array = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Convert grayscale image to BGR\n",
    "    back_to_rgb = cv2.cvtColor(img_array, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Resize the image\n",
    "    new_array = cv2.resize(back_to_rgb, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    # Reshape the image and convert it to a numpy array\n",
    "    x_input = np.array(new_array).reshape(1, IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "    # Display the image\n",
    "    plt.imshow(new_array)\n",
    "\n",
    "    # Normalize the image\n",
    "    x_input = x_input / 255.0\n",
    "\n",
    "    # Load the trained model and make a prediction\n",
    "    prediction = tf.keras.models.load_model(f'{MODELS_DIRECTORY}/{MODEL_FILE_NAME}').predict(x_input)\n",
    "\n",
    "    # Return the prediction\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cbaeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_on_single_image(f'{TRAINING_DATA_DIRECTORY}/Opened_Eyes/s0011_01518_0_0_1_0_0_01.png')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
